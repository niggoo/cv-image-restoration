{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-17T15:23:04.407870800Z",
     "start_time": "2023-11-17T15:23:04.249262600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "The directory 'test\\integrals' already exists.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Import libraries section ##\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import math\n",
    "# from LFR_utils import read_poses_and_images,pose_to_virtualcamera, init_aos, init_window\n",
    "from LFR.python.LFR_utils import read_poses_and_images, pose_to_virtualcamera, init_aos, init_window\n",
    "# import LFR_utils as utils\n",
    "import LFR.python.LFR_utils as utils\n",
    "import LFR.python.pyaos as pyaos\n",
    "import glm\n",
    "\n",
    "## path to where the results will be stored \n",
    "\n",
    "Download_Location = r'test'  ## Enter path to the directory where you want to save the results.\n",
    "print(Download_Location)\n",
    "Integral_Path = os.path.join(Download_Location,\n",
    "                             'integrals')  # Note that your results will be saved to this integrals folder.\n",
    "\n",
    "# Check if the directory already exists\n",
    "if not os.path.exists(Integral_Path):\n",
    "    os.mkdir(Integral_Path)\n",
    "else:\n",
    "    print(f\"The directory '{Integral_Path}' already exists.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-17T15:23:05.054460700Z",
     "start_time": "2023-11-17T15:23:04.411861100Z"
    }
   },
   "outputs": [],
   "source": [
    "#############################Start the AOS Renderer###############################################################\n",
    "w, h, fovDegrees = 512, 512, 50  # # resolution and field of view. This should not be changed.\n",
    "render_fov = 50\n",
    "\n",
    "if 'window' not in locals() or window == None:\n",
    "    window = pyaos.PyGlfwWindow(w, h, 'AOS')\n",
    "\n",
    "aos = pyaos.PyAOS(w, h, fovDegrees)\n",
    "\n",
    "set_folder = r'Enter path to your LFR/python directory'  # Enter path to your LFR/python directory\n",
    "aos.loadDEM(os.path.join(set_folder, 'zero_plane.obj'))\n",
    "\n",
    "####################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-17T15:23:05.088912Z",
     "start_time": "2023-11-17T15:23:05.063435300Z"
    }
   },
   "outputs": [],
   "source": [
    "#############################Create Poses for Initial Positions###############################################################\n",
    "\n",
    "# Below are certain functions required to convert the poses to a certain format to be compatabile with the AOS Renderer.\n",
    "\n",
    "def eul2rotm(theta):\n",
    "    s_1 = math.sin(theta[0])\n",
    "    c_1 = math.cos(theta[0])\n",
    "    s_2 = math.sin(theta[1])\n",
    "    c_2 = math.cos(theta[1])\n",
    "    s_3 = math.sin(theta[2])\n",
    "    c_3 = math.cos(theta[2])\n",
    "    rotm = np.identity(3)\n",
    "    rotm[0, 0] = c_1 * c_2\n",
    "    rotm[0, 1] = c_1 * s_2 * s_3 - s_1 * c_3\n",
    "    rotm[0, 2] = c_1 * s_2 * c_3 + s_1 * s_3\n",
    "\n",
    "    rotm[1, 0] = s_1 * c_2\n",
    "    rotm[1, 1] = s_1 * s_2 * s_3 + c_1 * c_3\n",
    "    rotm[1, 2] = s_1 * s_2 * c_3 - c_1 * s_3\n",
    "\n",
    "    rotm[2, 0] = -s_2\n",
    "    rotm[2, 1] = c_2 * s_3\n",
    "    rotm[2, 2] = c_2 * c_3\n",
    "\n",
    "    return rotm\n",
    "\n",
    "\n",
    "def createviewmateuler(eulerang, camLocation):\n",
    "    rotationmat = eul2rotm(eulerang)\n",
    "    translVec = np.reshape((-camLocation @ rotationmat), (3, 1))\n",
    "    conjoinedmat = (np.append(np.transpose(rotationmat), translVec, axis=1))\n",
    "    return conjoinedmat\n",
    "\n",
    "\n",
    "def divide_by_alpha(rimg2):\n",
    "    a = np.stack((rimg2[:, :, 3], rimg2[:, :, 3], rimg2[:, :, 3]), axis=-1)\n",
    "    return rimg2[:, :, :3] / a\n",
    "\n",
    "\n",
    "def pose_to_virtualcamera(vpose):\n",
    "    vp = glm.mat4(*np.array(vpose).transpose().flatten())\n",
    "    #vp = vpose.copy()\n",
    "    ivp = glm.inverse(glm.transpose(vp))\n",
    "    #ivp = glm.inverse(vpose)\n",
    "    Posvec = glm.vec3(ivp[3])\n",
    "    Upvec = glm.vec3(ivp[1])\n",
    "    FrontVec = glm.vec3(ivp[2])\n",
    "    lookAt = glm.lookAt(Posvec, Posvec + FrontVec, Upvec)\n",
    "    cameraviewarr = np.asarray(lookAt)\n",
    "    #print(cameraviewarr)\n",
    "    return cameraviewarr\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-17T15:23:05.254054400Z",
     "start_time": "2023-11-17T15:23:05.092904100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m [[ 1.  0. -0. -5.]\n",
      " [ 0.  1.  0.  0.]\n",
      " [ 0.  0.  1. 35.]]\n",
      "[[ 1.  0. -0. -5.]\n",
      " [ 0.  1.  0.  0.]\n",
      " [ 0.  0.  1. 35.]\n",
      " [ 0.  0.  0.  1.]]\n",
      "[[ 1.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.]\n",
      " [-0.  0.  1.  0.]\n",
      " [-5.  0. 35.  1.]]\n",
      "m [[ 1.  0. -0. -4.]\n",
      " [ 0.  1.  0.  0.]\n",
      " [ 0.  0.  1. 35.]]\n",
      "[[ 1.  0. -0. -4.]\n",
      " [ 0.  1.  0.  0.]\n",
      " [ 0.  0.  1. 35.]\n",
      " [ 0.  0.  0.  1.]]\n",
      "[[ 1.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.]\n",
      " [-0.  0.  1.  0.]\n",
      " [-4.  0. 35.  1.]]\n",
      "m [[ 1.  0. -0. -3.]\n",
      " [ 0.  1.  0.  0.]\n",
      " [ 0.  0.  1. 35.]]\n",
      "[[ 1.  0. -0. -3.]\n",
      " [ 0.  1.  0.  0.]\n",
      " [ 0.  0.  1. 35.]\n",
      " [ 0.  0.  0.  1.]]\n",
      "[[ 1.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.]\n",
      " [-0.  0.  1.  0.]\n",
      " [-3.  0. 35.  1.]]\n",
      "m [[ 1.  0. -0. -2.]\n",
      " [ 0.  1.  0.  0.]\n",
      " [ 0.  0.  1. 35.]]\n",
      "[[ 1.  0. -0. -2.]\n",
      " [ 0.  1.  0.  0.]\n",
      " [ 0.  0.  1. 35.]\n",
      " [ 0.  0.  0.  1.]]\n",
      "[[ 1.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.]\n",
      " [-0.  0.  1.  0.]\n",
      " [-2.  0. 35.  1.]]\n",
      "m [[ 1.  0. -0. -1.]\n",
      " [ 0.  1.  0.  0.]\n",
      " [ 0.  0.  1. 35.]]\n",
      "[[ 1.  0. -0. -1.]\n",
      " [ 0.  1.  0.  0.]\n",
      " [ 0.  0.  1. 35.]\n",
      " [ 0.  0.  0.  1.]]\n",
      "[[ 1.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.]\n",
      " [-0.  0.  1.  0.]\n",
      " [-1.  0. 35.  1.]]\n",
      "m [[ 1.  0. -0.  0.]\n",
      " [ 0.  1.  0.  0.]\n",
      " [ 0.  0.  1. 35.]]\n",
      "[[ 1.  0. -0.  0.]\n",
      " [ 0.  1.  0.  0.]\n",
      " [ 0.  0.  1. 35.]\n",
      " [ 0.  0.  0.  1.]]\n",
      "[[ 1.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.]\n",
      " [-0.  0.  1.  0.]\n",
      " [ 0.  0. 35.  1.]]\n",
      "m [[ 1.  0. -0.  1.]\n",
      " [ 0.  1.  0.  0.]\n",
      " [ 0.  0.  1. 35.]]\n",
      "[[ 1.  0. -0.  1.]\n",
      " [ 0.  1.  0.  0.]\n",
      " [ 0.  0.  1. 35.]\n",
      " [ 0.  0.  0.  1.]]\n",
      "[[ 1.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.]\n",
      " [-0.  0.  1.  0.]\n",
      " [ 1.  0. 35.  1.]]\n",
      "m [[ 1.  0. -0.  2.]\n",
      " [ 0.  1.  0.  0.]\n",
      " [ 0.  0.  1. 35.]]\n",
      "[[ 1.  0. -0.  2.]\n",
      " [ 0.  1.  0.  0.]\n",
      " [ 0.  0.  1. 35.]\n",
      " [ 0.  0.  0.  1.]]\n",
      "[[ 1.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.]\n",
      " [-0.  0.  1.  0.]\n",
      " [ 2.  0. 35.  1.]]\n",
      "m [[ 1.  0. -0.  3.]\n",
      " [ 0.  1.  0.  0.]\n",
      " [ 0.  0.  1. 35.]]\n",
      "[[ 1.  0. -0.  3.]\n",
      " [ 0.  1.  0.  0.]\n",
      " [ 0.  0.  1. 35.]\n",
      " [ 0.  0.  0.  1.]]\n",
      "[[ 1.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.]\n",
      " [-0.  0.  1.  0.]\n",
      " [ 3.  0. 35.  1.]]\n",
      "m [[ 1.  0. -0.  4.]\n",
      " [ 0.  1.  0.  0.]\n",
      " [ 0.  0.  1. 35.]]\n",
      "[[ 1.  0. -0.  4.]\n",
      " [ 0.  1.  0.  0.]\n",
      " [ 0.  0.  1. 35.]\n",
      " [ 0.  0.  0.  1.]]\n",
      "[[ 1.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.]\n",
      " [-0.  0.  1.  0.]\n",
      " [ 4.  0. 35.  1.]]\n",
      "m [[ 1.  0. -0.  5.]\n",
      " [ 0.  1.  0.  0.]\n",
      " [ 0.  0.  1. 35.]]\n",
      "[[ 1.  0. -0.  5.]\n",
      " [ 0.  1.  0.  0.]\n",
      " [ 0.  0.  1. 35.]\n",
      " [ 0.  0.  0.  1.]]\n",
      "[[ 1.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.]\n",
      " [-0.  0.  1.  0.]\n",
      " [ 5.  0. 35.  1.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pauld\\miniconda3\\envs\\cvproj\\lib\\site-packages\\ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########################## Below we generate the poses for rendering #####################################\n",
    "# This is based on how renderer is implemented. \n",
    "\n",
    "Numberofimages = 11  # Or just the number of images\n",
    "Focal_plane = 0  # Focal plane is set to the ground so it is zero.\n",
    "\n",
    "# ref_loc is the reference location or the poses of the images. The poses are the same for the dataset and therefore only the images have to be replaced.\n",
    "\n",
    "ref_loc = [[5, 4, 3, 2, 1, 0, -1, -2, -3, -4, -5], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "                                                    0]]  # These are the x and y positions of the images. It is of the form [[x_positions],[y_positions]]\n",
    "\n",
    "altitude_list = [35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35]  # [Z values which is the height]\n",
    "\n",
    "center_index = 5  # this is important, this will be the pose index at which the integration should happen. For example if you have 5 images, lets say you want to integrate all 5 images to the second image position. Then your center_index is 1 as index starts from zero.\n",
    "\n",
    "site_poses = []\n",
    "for i in range(Numberofimages):\n",
    "    EastCentered = (ref_loc[0][i] - 0.0)  #Get MeanEast and Set MeanEast\n",
    "    NorthCentered = (0.0 - ref_loc[1][i])  #Get MeanNorth and Set MeanNorth\n",
    "    M = createviewmateuler(np.array([0.0, 0.0, 0.0]), np.array([ref_loc[0][i], ref_loc[1][i], - altitude_list[i]]))\n",
    "    print('m', M)\n",
    "    ViewMatrix = np.vstack((M, np.array([0.0, 0.0, 0.0, 1.0], dtype=np.float32)))\n",
    "    print(ViewMatrix)\n",
    "    camerapose = np.asarray(ViewMatrix.transpose(), dtype=np.float32)\n",
    "    print(camerapose)\n",
    "    site_poses.append(\n",
    "        camerapose)  # site_poses is a list now containing all the poses of all the images in a certain format that is accecpted by the renderer.\n",
    "\n",
    "#############################Read the generated images from the simulator and store in a list ###############################################################\n",
    "\n",
    "import re\n",
    "\n",
    "numbers = re.compile(r'(\\d+)')\n",
    "\n",
    "\n",
    "def numericalSort(value):\n",
    "    parts = numbers.split(value)\n",
    "    parts[1::2] = map(int, parts[1::2])\n",
    "    return parts\n",
    "\n",
    "\n",
    "imagelist = []\n",
    "\n",
    "import glob\n",
    "\n",
    "for img in sorted(glob.glob(r\"test/test_input_images\" + '/*.png'),\n",
    "                  key=numericalSort):  # Enter path to the images directory which should contain 11 images.\n",
    "    n = cv2.imread(img)\n",
    "    imagelist.append(n)\n",
    "\n",
    "aos.clearViews()  # Every time you call the renderer you should use this line to clear the previous views  \n",
    "for i in range(len(imagelist)):\n",
    "    aos.addView(imagelist[i], site_poses[i], \"DEM BlobTrack\")  # Here we are adding images to the renderer one by one.\n",
    "aos.setDEMTransform([0, 0, Focal_plane])\n",
    "\n",
    "proj_RGBimg = aos.render(pose_to_virtualcamera(site_poses[center_index]), render_fov)\n",
    "tmp_RGB = divide_by_alpha(proj_RGBimg)\n",
    "cv2.imwrite(os.path.join(Integral_Path, 'integral.png'),\n",
    "            tmp_RGB)  # Final result. Check the integral result in the integrals folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T15:23:05.269013600Z",
     "start_time": "2023-11-17T15:23:05.256049100Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c0546a8624a4a236bae0f9fea37c96b2936c9ad1821cd89b71f7783537db0568"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
